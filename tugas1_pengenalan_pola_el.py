# -*- coding: utf-8 -*-
"""Tugas1_Pengenalan Pola_EL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O_Cv-W0U5i3txHDskWYCinAtWb3rOtdE

## üåª**Destyasti Sri Puspito Widi_24/554312/NPA/19974**üåª
"""

import os
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Dropout, Flatten, Dense
import joblib

"""Mount Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""Akses Folder Dataset di Google Drive"""

# path dataset
dataset_path = "/content/drive/MyDrive/PengenalanPola_desty/UCI HAR Dataset"

# check apakah folder dataset ada
if os.path.exists(dataset_path):
    print("‚úÖ Dataset ditemukan!")
else:
    print("‚ùå Dataset tidak ditemukan. Pastikan path benar.")

"""Load Dataset ke Pandas DataFrame"""

# Pastikan path sesuai lokasi dataset di Google Drive
dataset_path = "/content/drive/MyDrive/PengenalanPola_desty/UCI HAR Dataset"

def load_data(prefix):
    """Memuat data dari folder train/test dengan validasi file"""

    # Path untuk features.txt
    features_path = f"{dataset_path}/features.txt"

    # Periksa apakah features.txt ada
    if not os.path.exists(features_path):
        raise FileNotFoundError(f"‚ùå File {features_path} tidak ditemukan!")

    # Memuat fitur dari features.txt
    features = pd.read_csv(features_path, sep='\s+', header=None)[1].values

    # Mengatasi fitur yang duplikat
    unique_features = []
    feature_counts = {}
    for feature in features:
        if feature in feature_counts:
            feature_counts[feature] += 1
            unique_features.append(f"{feature}_{feature_counts[feature]}")
        else:
            feature_counts[feature] = 1
            unique_features.append(feature)

    # Path untuk data X dan y
    X_path = f"{dataset_path}/{prefix}/X_{prefix}.txt"
    y_path = f"{dataset_path}/{prefix}/y_{prefix}.txt"

    # Periksa apakah file X dan y ada sebelum membaca
    if not os.path.exists(X_path):
        raise FileNotFoundError(f"‚ùå File {X_path} tidak ditemukan!")
    if not os.path.exists(y_path):
        raise FileNotFoundError(f"‚ùå File {y_path} tidak ditemukan!")

    # Memuat data X (fitur) dan y (label)
    X = pd.read_csv(X_path, sep='\s+', header=None, names=unique_features)
    y = pd.read_csv(y_path, sep='\s+', header=None, names=['Activity'])

    return X, y, unique_features

# load data train dan test
try:
    X_train, y_train, feature_names = load_data("train")
    X_test, y_test, _ = load_data("test")  # Tidak perlu feature_names lagi
    print("‚úÖ Data berhasil dimuat!")
except FileNotFoundError as e:
    print(e)
except Exception as e:
    print(f"‚ùå Terjadi error: {e}")
print("========================================================")
# Cek bentuk data
print(f"Training Data: {X_train.shape}, Labels: {y_train.shape}")
print(f"Testing Data: {X_test.shape}, Labels: {y_test.shape}")
print("========================================================")

"""Preprocessing: Normalisasi & Encoding Label"""

# Normalisasi fitur
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Encoding label aktivitas (1-6 ‚Üí 0-5)
encoder = LabelEncoder()
y_train = encoder.fit_transform(y_train.values.ravel())
y_test = encoder.transform(y_test.values.ravel())

print("‚úÖ Data siap untuk training!")

"""Training Model menggunakan Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluasi model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"‚úÖ Accuracy: {accuracy:.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred))

"""Training Menggunakan Model Deep Learning dengan CNN"""

# Pastikan X_train dan X_test dalam bentuk NumPy array
X_train_np = np.array(X_train)  # Jika masih dalam bentuk DataFrame
X_test_np = np.array(X_test)

# Bentuk ulang untuk CNN (tambahkan dimensi ke-3)
X_train_cnn = X_train_np.reshape(X_train_np.shape[0], X_train_np.shape[1], 1)
X_test_cnn = X_test_np.reshape(X_test_np.shape[0], X_test_np.shape[1], 1)


# Model CNN
model_cnn = Sequential([
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    Dropout(0.3),
    Conv1D(32, kernel_size=3, activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(6, activation='softmax')  # 6 Kelas aktivitas
])


# Compile & Train
model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model_cnn.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test))

# Evaluasi
loss, acc = model_cnn.evaluate(X_test_cnn, y_test)
print(f"‚úÖ CNN Accuracy: {acc:.4f}")

"""Simpan Model"""

# Simpan model Random Forest
joblib.dump(model, "/content/drive/MyDrive/model_rf.pkl")

# Simpan model CNN
model_cnn.save("/content/drive/MyDrive/model_cnn.h5")

!pip install tensorflow

import tensorflow as tf
model_cnn = tf.keras.models.load_model("/content/drive/MyDrive/model_cnn.h5")
model_rf = joblib.load("/content/drive/MyDrive/model_rf.pkl")

"""Confusion Matrix dari Testing Menggunkan CNN"""

# klasifikasi class
y_pred_prob = model_cnn.predict(X_test_cnn) # klasifikasi probabilitas
y_pred = np.argmax(y_pred_prob, axis=1)  # Konversi ke label class

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Purples", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.xlabel("klasifikasi Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix_Testing Data")
plt.show()

"""## üîé**INPUT DAN OUTPUT_PROGRAM HAR SINYAL 1 DIMENSI**üîé

Membuat sinyal acak untuk pengujian/ Input Program
"""

# Buat sinyal acak dengan 561 angka (mirip data dari sensor)
random_signal = np.random.uniform(-1, 1, 561)  # Angka acak antara -1 dan 1

# Konversi ke format string agar bisa digunakan sebagai input
random_signal_str = ",".join(map(str, random_signal))

# Tampilkan sinyal lengkap
print("Copy random sinyal ini dan Inputkan sinyal:")
print(random_signal_str)
print("=======================================================================================================")

# Visualisasi sinyal menggunakan Matplotlib
plt.figure(figsize=(12, 5))
plt.plot(random_signal, linestyle='-', color='b', linewidth=1, alpha=0.8, label="Random Sensor Signal")
plt.xlabel("Time (Sample Index)")
plt.ylabel("Amplitude")
plt.title("Random Sensor Signal Visualization")
plt.legend()
plt.grid(True)
plt.show()

def predict_activity(input_signal, model, scaler, encoder, feature_names):
    """
    Mengklasifikasi aktivitas berdasarkan input sinyal.

    Parameters:
    - input_signal: list atau array (satu sampel data dengan panjang sesuai jumlah fitur)
    - model: model Machine Learning yang telah dilatih
    - scaler: StandardScaler yang telah dilatih dengan data training
    - encoder: LabelEncoder untuk mengonversi hasil Klasifikasi menjadi label aktivitas
    - feature_names: Nama fitur agar sesuai dengan data training

    Returns:
    - Klasifikasi aktivitas sebagai teks
    """
    # Pastikan input dalam bentuk DataFrame agar sesuai dengan scaler
    input_df = pd.DataFrame([input_signal], columns=feature_names)

    # Lakukan scaling menggunakan scaler yang sudah dilatih
    input_scaled = scaler.transform(input_df)

    # Lakukan Klasifikasi dengan model
    klasifikasi_class = model.predict(input_scaled)

    # Konversi hasil Klasifikasi ke label aktivitas
    klasifikasi_label = encoder.inverse_transform([klasifikasi_class[0]])[0]

    # Pemetaan label angka ke aktivitas
    activity_labels = {
        1: "Walking (Berjalan)",
        2: "Walking Upstairs (Naik Tangga)",
        3: "Walking Downstairs (Turun Tangga)",
        4: "Sitting (Duduk)",
        5: "Standing (Berdiri)",
        6: "Laying (Berbaring)"
    }

    activity_name = activity_labels.get(klasifikasi_label, "Unknown Activity")

    return activity_name

# Menampilkan menu untuk memasukkan data secara manual
print("Inputkan sinyal dengan format angka yang dipisahkan koma (,)")

# Input dari pengguna
input_str = input("Inputkan Sinyal: ")
print("======================================================================================================")
# Konversi input string ke array float
try:
    input_signal = np.array([float(x) for x in input_str.split(",")])

    # Pastikan jumlah fitur sesuai
    if len(input_signal) != len(feature_names):
        print(f"‚ùå Jumlah fitur tidak sesuai! Harus {len(feature_names)} angka.")
    else:
        # Plot sinyal input
        plt.figure(figsize=(10, 4))
        plt.plot(input_signal, marker='o', linestyle='-', color='b', label="Input Signal")
        plt.xlabel("Feature Index")
        plt.ylabel("Feature Value")
        plt.title("Visualization of Input Signal")
        plt.legend()
        plt.grid(True)
        plt.show()
        # klasifikasi aktivitas dari input sinyal
        klasifikasi_activity = predict_activity(input_signal, model, scaler, encoder, feature_names)
        print("======================================================================================================")
        print(f"‚úÖ Klasifikasi Aktivitas: {klasifikasi_activity}")
except ValueError:
    print("‚ùå Format input tidak valid! Masukkan angka yang dipisahkan koma (,)")